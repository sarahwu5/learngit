# 1

如果你有一个形状为[T]的一维张量，使用unsqueeze(-1)后，张量的形状将变为[T, 1]。这与unsqueeze(1)的效果相同，因为对于一维张量来说，第一个维度和最后一个维度是同一个维度。  
当我们对这个一维张量执行unsqueeze(1)操作时，我们在第二个维度（索引为1）插入一个新的维度，大小为1。  
这个操作的效果可以形象地理解为将一维张量“竖起来”，使其变成一个列向量。每个元素现在都被视为一个单独的列向量，每个列向量的长度为1。  
unsqueeze(-1)函数的作用是在张量的最后一个维度后面插入一个新的维度，这个新维度的大小为1。这里的-1表示张量维度的最后一个位置。

# 2
在PyTorch中，表达式`1 - self.alpha[0:upper_bound]`涉及到张量的切片和基本的算术运算。让我们逐步分解这个表达式：

1. **`self.alpha`**：这是一个张量，可能是一维或多维的。

2. **`self.alpha[0:upper_bound]`**：这是一个切片操作，它从张量`self.alpha`中选取从索引0开始到索引`upper_bound`（不包括`upper_bound`）的所有元素。这意味着你得到了一个子张量，包含`self.alpha`的前`upper_bound`个元素。

3. **`1 - self.alpha[0:upper_bound]`**：这是一个逐元素的减法操作。数字1是一个标量，它从切片得到的子张量的每个元素中减去。结果是一个与子张量形状相同的新张量。

例如，如果`self.alpha`是一个形状为`[5]`的张量，其值为`[0.1, 0.2, 0.3, 0.4, 0.5]`，且`upper_bound`是3，那么：

```python
import torch

self.alpha = torch.tensor([0.1, 0.2, 0.3, 0.4, 0.5])
upper_bound = 3
result = 1 - self.alpha[0:upper_bound]
print(result)
```

输出结果将是：

```
tensor([0.9, 0.8, 0.7])
```

这里，`1 - self.alpha[0:upper_bound]`计算了标量1与子张量`[0.1, 0.2, 0.3]`的逐元素差，得到了结果`[0.9, 0.8, 0.7]`。

这种操作在处理序列数据或执行元素级计算时非常有用，特别是在需要根据某些条件调整张量值的场景中。

# 3
矩阵乘法要求左矩阵的列数等于右矩阵的行数，结果矩阵的形状将是左矩阵的行数乘以右矩阵的列数。  
在NumPy和PyTorch等科学计算库中，* 运算符通常用于执行元素级乘法（也称为哈达玛积），而不是矩阵乘法。这意味着两个数组的对应元素相乘，而不是执行线性代数中的矩阵乘法。这种运算要求两个数组的形状完全相同，或者至少在每个维度上是兼容的，以便应用广播规则。  
*运算符用于元素级乘法，而矩阵乘法需要使用 @ 运算符或 np.dot(A, B) 函数。这两种运算在数学上和应用上都是不同的。